{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6965398c",
   "metadata": {},
   "source": [
    "### Student Number : 2\n",
    "#### Alexandre Lemonnier (alexandre.lemonnier)\n",
    "#### Victor Simonin (victor.simonin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e20fec",
   "metadata": {},
   "source": [
    "First, let's import our useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02201986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44015ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_application_name = \"Projet_LAVS\"\n",
    "spark = (SparkSession.builder.appName(spark_application_name).getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0ffb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = [StructField(\"Date\",TimestampType()), StructField(\"High\",FloatType()), StructField(\"Low\",FloatType()), StructField(\"Open\",FloatType()), StructField(\"Close\",FloatType()), StructField(\"Volume\",IntegerType()), StructField(\"Adj Close\",FloatType()), StructField(\"company_name\",StringType())]\n",
    "Schema = StructType(Columns)\n",
    "\n",
    "def read_data(path):\n",
    "    return spark.read.schema(Schema).csv(path, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee95fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = read_data('data/AMAZON.csv')\n",
    "apple = read_data('data/APPLE.csv')\n",
    "facebook = read_data('data/FACEBOOK.csv')\n",
    "google = read_data('data/GOOGLE.csv')\n",
    "microsoft = read_data('data/MICROSOFT.csv')\n",
    "tesla = read_data('data/TESLA.csv')\n",
    "zoom = read_data('data/ZOOM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a672e8b",
   "metadata": {},
   "source": [
    "Now let's do the exploration of our datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e3e2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploration(dataset):\n",
    "    print(\"Exploration of the dataset\", dataset.head().company_name)\n",
    "    '''\n",
    "    print(\"\\nThe 40 first elements : \")\n",
    "    for el in dataset.head(40):\n",
    "        print(el)\n",
    "        \n",
    "    print(\"\\nThe 40 Last elements : \")\n",
    "    for el in dataset.tail(40):\n",
    "        print(el)\n",
    "    ''' \n",
    "        \n",
    "    print(\"\\nThe total number of observations is\", dataset.count())\n",
    "    \n",
    "    print(\"\\nThe first date is\", dataset.head().Date)\n",
    "    print(\"The second date is\", dataset.head(2)[1].Date)\n",
    "    print(\"So we deduce the priod between the data points is a Day\")\n",
    "    \n",
    "    print(\"\\nSome statistics :\")\n",
    "    print(dataset.summary().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2338d4d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploration of the dataset AMAZON\n",
      "\n",
      "The total number of observations is 987\n",
      "\n",
      "The first date is 2017-01-03 00:00:00\n",
      "The second date is 2017-01-04 00:00:00\n",
      "So we deduce the priod between the data points is a Day\n",
      "\n",
      "Some statistics :\n",
      "+-------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------+\n",
      "|summary|              High|               Low|             Open|             Close|           Volume|         Adj Close|company_name|\n",
      "+-------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------+\n",
      "|  count|               987|               987|              987|               987|              987|               987|         987|\n",
      "|   mean|1762.0071216958152|1722.1011452099956|1743.433881363487|1742.9566644206718| 4509728.05775076|1742.9566644206718|        null|\n",
      "| stddev| 667.2385315752688| 644.7988093382758|657.1153070927137| 655.9576061129322|2179817.628631287| 655.9576061129322|        null|\n",
      "|    min|            758.76|             747.7|           757.92|            753.67|           881300|            753.67|      AMAZON|\n",
      "|    25%|            1191.0|            1176.0|           1188.3|            1186.1|          2982700|            1186.1|        null|\n",
      "|    50%|           1756.96|           1719.23|          1742.24|           1739.65|          3925600|           1739.65|        null|\n",
      "|    75%|           1941.59|           1900.34|          1922.98|           1918.19|          5429100|           1918.19|        null|\n",
      "|    max|           3552.25|           3486.69|           3547.0|           3531.45|         16565000|           3531.45|      AMAZON|\n",
      "+-------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "exploration(amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d90d406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c4d039b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'isnan(Date)' due to data type mismatch: argument 1 requires (double or float) type, however, 'Date' is of timestamp type.;\n'Aggregate [count(CASE WHEN (isnan(Date#136) OR isnull(Date#136)) THEN Date END) AS Date#3456, count(CASE WHEN (isnan(High#137) OR isnull(High#137)) THEN High END) AS High#3458L, count(CASE WHEN (isnan(Low#138) OR isnull(Low#138)) THEN Low END) AS Low#3460L, count(CASE WHEN (isnan(Open#139) OR isnull(Open#139)) THEN Open END) AS Open#3462L, count(CASE WHEN (isnan(Close#140) OR isnull(Close#140)) THEN Close END) AS Close#3464L, count(CASE WHEN (isnan(cast(Volume#141 as double)) OR isnull(Volume#141)) THEN Volume END) AS Volume#3466L, count(CASE WHEN (isnan(Adj Close#142) OR isnull(Adj Close#142)) THEN Adj Close END) AS Adj Close#3468L, count(CASE WHEN (isnan(cast(company_name#143 as double)) OR isnull(company_name#143)) THEN company_name END) AS company_name#3470L]\n+- Relation [Date#136,High#137,Low#138,Open#139,Close#140,Volume#141,Adj Close#142,company_name#143] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mamazon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misNull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mamazon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols):\n\u001b[1;32m   1665\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1685\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'isnan(Date)' due to data type mismatch: argument 1 requires (double or float) type, however, 'Date' is of timestamp type.;\n'Aggregate [count(CASE WHEN (isnan(Date#136) OR isnull(Date#136)) THEN Date END) AS Date#3456, count(CASE WHEN (isnan(High#137) OR isnull(High#137)) THEN High END) AS High#3458L, count(CASE WHEN (isnan(Low#138) OR isnull(Low#138)) THEN Low END) AS Low#3460L, count(CASE WHEN (isnan(Open#139) OR isnull(Open#139)) THEN Open END) AS Open#3462L, count(CASE WHEN (isnan(Close#140) OR isnull(Close#140)) THEN Close END) AS Close#3464L, count(CASE WHEN (isnan(cast(Volume#141 as double)) OR isnull(Volume#141)) THEN Volume END) AS Volume#3466L, count(CASE WHEN (isnan(Adj Close#142) OR isnull(Adj Close#142)) THEN Adj Close END) AS Adj Close#3468L, count(CASE WHEN (isnan(cast(company_name#143 as double)) OR isnull(company_name#143)) THEN company_name END) AS company_name#3470L]\n+- Relation [Date#136,High#137,Low#138,Open#139,Close#140,Volume#141,Adj Close#142,company_name#143] csv\n"
     ]
    }
   ],
   "source": [
    "amazon.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in amazon.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b4884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
