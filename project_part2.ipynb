{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Number : 2\n",
    "#### Alexandre Lemonnier (alexandre.lemonnier) (23077)\n",
    "#### Victor Simonin (victor.simonin) (23093)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import our useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, isnull, mean, abs, max, avg, lag, lead, udf, struct, lit, variance, weekofyear, month, year\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import timedelta, datetime\n",
    "from pyspark.ml.stat import Correlation\n",
    "from sklearn.preprocessing import normalize\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import *\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_application_name = \"Projet_LAVS\"\n",
    "spark = (SparkSession.builder.appName(spark_application_name).getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the structure of the schema and its columns with their relative types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [StructField(\"Date\",TimestampType()), StructField(\"High\",FloatType()), StructField(\"Low\",FloatType()), StructField(\"Open\",FloatType()), StructField(\"Close\",FloatType()), StructField(\"Volume\",FloatType()), StructField(\"Adj Close\",FloatType()), StructField(\"company_name\",StringType())]\n",
    "schema = StructType(columns)\n",
    "\n",
    "def read_data(path):\n",
    "    return spark.read.schema(schema).csv(path, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read all the stocks' data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = read_data('data/AMAZON.csv')\n",
    "apple = read_data('data/APPLE.csv')\n",
    "facebook = read_data('data/FACEBOOK.csv')\n",
    "google = read_data('data/GOOGLE.csv')\n",
    "microsoft = read_data('data/MICROSOFT.csv')\n",
    "tesla = read_data('data/TESLA.csv')\n",
    "zoom = read_data('data/ZOOM.csv')\n",
    "datasets = [amazon, apple, facebook, google, microsoft, tesla, zoom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll(*dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)\n",
    "df_stocks = unionAll(*datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close', 'company_name']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, High: string, Low: string, Open: string, Close: string, Volume: string, Adj Close: string, company_name: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocks.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "outputPath = \"data/stocks.csv\"\n",
    "\n",
    "df_stocks.write.mode(\"overwrite\").csv(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5102 rows in the training set, and 1231 in the test set\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = df_stocks.randomSplit([.8, .2], seed=42)\n",
    "print(f\"There are {trainDF.cache().count()} rows in the training set, and {testDF.cache().count()} in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|company_name|count|\n",
      "+------------+-----+\n",
      "|      AMAZON|  828|\n",
      "|       APPLE|  794|\n",
      "|    FACEBOOK|  787|\n",
      "|      GOOGLE|  793|\n",
      "|   MICROSOFT|  768|\n",
      "|       TESLA|  794|\n",
      "|        ZOOM|  338|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy(\"company_name\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|company_name|count|\n",
      "+------------+-----+\n",
      "|      AMAZON|  159|\n",
      "|       APPLE|  193|\n",
      "|    FACEBOOK|  200|\n",
      "|      GOOGLE|  194|\n",
      "|   MICROSOFT|  219|\n",
      "|       TESLA|  193|\n",
      "|        ZOOM|   73|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.groupBy(\"company_name\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
